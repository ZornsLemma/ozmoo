Benchmarks after reworking sideways RAM paging:

Baseline is 87f85b82608f6072ebeaebd0dfde488931e00c42 acorn-swr branch latest - this always uses "old-style no tweaks bigdyn":
Using b-em Master 128 mode with 64K sideways RAM in mode 7 for all tests
Drive noises off: $004d84 (repeat $004d83)
Drive noises on: $0051c2 (repeat $0051c2)

Comparison is latest acorn-wip 30ebfe64c647828c2716e0e3b49027d80479af11
bigdyn: 
Drive noises off: $0049a4 95.0% (repeat $0049a5)
Drive noises on: $004e0b 95.5% (repeat $004e0b)

smalldyn:
Drive noises off: $0045c0 90.0% (repeat $0045bf)
Drive noises on: $004a00 90.5% (repeat $004a00)




Register use analysis:

read_byte_at_z_address:
- returns value read in A
- upstream code looks like X has a pretty arbitrary value on exit
- upstream code will always (?) return with Y=0 but I don't believe any caller relies on that
- called by get_page_at_z_pc{,_did_pha}
- called by .initial_copy_loop in C64 disk code, but that immediately trashes A, X and Y after call
- called by read_next_byte, which explicitly preserves its caller's Y and doesn't use the Y=0 return
- called by .copy_table_common, which immediately does ldy #0 after calling it and trashes X a dozen or so instructions later
- no other callers
- so I think this is allowed to corrupt X and Y

get_page_at_z_pc{,_did_pha}:
- contains upstream code to explicitly preserve A and X
- upstream code explicitly returns with Y=0 and has a comment saying this is important
- calls read_byte_at_z_address
- called by C64 restore_game, which immediately does lda and ldx afterwards - there is no clear use of Y in the following code, and I am 99% confident it doesn't matter
- called by inc_z_pc_page
- called by z_init, which will trash A, X and Y not longer afterwards
- so I think this can maybe corrupt Y, provided read_next_byte_at_z_pc takes its own steps to ensure Y=0 (and I'm not sure that's actually necessary)

read_next_byte:
- returns value in A
- upstream code explicitly preserves caller's Y
- calls read_byte_at_z_address
- upstream code will return with the X value from read_byte_at_z_address, which is pretty arbitrary
- has many callers, not analysed
- so I think this is allowed to corrupt X

inc_z_pc_page:
- upstream code explicitly preserves A
- X and Y are altered iff get_page_at_z_pc_did_pha is called and alters them; it explicitly preserves X, so inc_z_pc_page will also preserve X, and it may (depending on whether get_page... is called) set Y to 0
- called only by read_next_byte_at_z_pc

read_next_byte_at_z_pc:
- returns result in A
- upstream code will always return with Y=0, because it sets Y=0 and *maybe* calls inc_z_pc_page, which will also set Y=0
- will preserve X
- has many callers, some of which rely on it preserving X
- I can't see any callers obviously depending on Y=0 but I can't be 100% sure there isn't something I'm missing - I am 95% confident having looked at the callers this isn't a problem, and in practice it really doesn't seem to break anything having Y!=0 on exit












On C64 the game normally keeps I/O+ROM paged in from $D000 upwards; copy_page
is used to copy RAM around with RAM paged in from $D000 upwards. The vmem_cache
stuff keeps a copy of high RAM pages currently in use in low RAM. This is
accessible RAM caching inaccessible RAM; it has nothing to do with optimising
disc access. On Acorn second processor builds this is irrelevant as there's no
paging. SFTODONOW: I suspect this is also irrelevant on Acorn SWR builds, but I
need to investigate exactly how Z-machine non-dynamic memory is accessed to see
if we can ensure the correct SWR bank is paged in at all times without using
this caching mechanisms.

mempointer is read in get_page_at_z_pc immediately after calling read_byte_at_z_address - it is copied into z_pc_mempointer+1
ditto: in initial_copy_loop (REU code)
read_byte_at_z_address updates mempointer; a fast path relies on mempointer+1 being consistent with zp_pc_[lh]
read_byte_at_z_address updates zp_pc_[lh]
read_next_byte uses read_byte_at_z_address to read the address at z_address+[012], it then advances z_address+[012]
copy_table_common uses read_byte_at_z_address
zp_pc_[lh] are really only used in vmem.asm instead read_byte_at_z_address; I think they basically boil down to "what page of Z-machine memory does mempointer currently point to?" as an optimisation.

I'm struggling to see why we have both mempointer and zp_pc_mempointer.
I *think* zp_pc_mempointer is used for the Z-machine program counter, and this may be allowed to be "separate" to mempointer. I see that the *cache* support refuses to evict a cache page if zp_pc_mempointer is referring to it, but I don't see anything in the disc<->RAM stuff which would stop a vmem page being discarded if zp_pc_mempointer refers to it.
Yes, I think that's basically it
- mempointer is used for data access, and is also moved in the process of updating zp_pc_mempointer but that's OK because we don't rely on mempointer pointing to any one place except in the short term
- I still can't see anything protecting vmem pages being used by zp_pc_mempointer being evicted, although I suppose short of extreme memory pressure (which we might see on a hypothetical 32K RAM port) this won't happen - I could potentially tweak the vmem eviction code to check against zp_pc_mempointer - one possible way to do this easily would be just under .no_such_block to set the tick on the vmem block containing the PC (we could keep a copy of the index when we do the new-page stuff for z-pc) to a very recent value - then again it might well be as easy just to tweak the chosen code - ah no, it looks OK (of course), just under .no_such_block we have "; Skip if z_pc points here" so this is fine
- since only (?) read_byte_at_z_address can discard pages from vmem, mempointer is always going to be safe from eviction - read_byte_at_z_address is what sets mempointer

I suspect on a SWR build, we would keep the bank containing z_pc_mempointer paged in at all times. read_byte_at_z_address would be used for reads of data, and it would briefly page in the relevant bank. We would probably need to tweak the logic when the Z-machine PC is being moved and might call into read_byte_at_z_address so we don't get into a loop - actually it would probably be fine, but it would be silly to page back in the old PC bank just to revert to paging in the new PC bank in the caller of read_byte_at_z_address in the PC update code.
- we *could* use the C64-ish cache mechanism to avoid this, but I don't think we need to - the C64 presumably needs its high ROM banked in for kernal interrupts and keyboard reading and so forth, whereas the SWR on the Acorn isn't conflicting with the OS and we can safely keep it paged in all the time, it's just a question of ensuring we cope when the PC and "data" reads are from different SWR banks.

I think zp_pc_[lh] are *not* related to the Z-machine PC; they may be misnamed, or "pc" may stand for something else, or of course I might have the wrong end of the stick.



Loading a $C800 byte preload file using readblocks (2 pages at a time) took (b-em, drive noises on, timings via kernal_readtime):
Master Turbo OS 3.2 - 8.22s
DFS 0.9 with Turbo copro - 8.0s
DFS 2.26 with Turbo copro - 8.2s
compared with OSFILE:
Master Turbo OS 3.2 - 7.62s
DFS 0.9 with Turbo copro - 7.62s
DFS 2.26 with Turbo copro - 7.62s
- so it looks as though giving up PRELOAD and using readblocks to do the initial load (which would simplify things if I have two different-sized preloads and/or if I start interleaving across both sides of the disc) is not a significant performance hit



Biggish chunks of data for initial move to $400:
.jmp_buf max 257 bytes but in reality much smaller, not measured/analysed yet


Empirically working out .jmp_buf storage requirement: poking stack page full of $EA and running benchmark then examining stack afterwards, it looks like we never got down below $1E0 (and some of that may be interrupts below our stack, which don't count for .jmp_buf purposes).
Skimming the call code, it doesn't look like Z machine function calls build up state on the 6502 stack - this makes sense, as otherwise a save/restore wouldn't restore that state correctly. So I don't think a sufficiently convoluted program running on Ozmoo can't provoke higher-than-normal 6502 stack use.
